Zunächst habe ich versucht, die Anwendung aus der Aufgabenstellung in eine formale Problemstellung zu übersetzen:
\begin{displayquote}
	Gegeben ist ein ein gerichteter Graph \(G=(V,E)\)\footnote{\(V_{ertices}\) ist die Menge der Knoten (Firmen), \(E_{dges}\) die Menge der Kanten (Nebenbedingungen)} mit gewichteten Knoten\footnote{Das Gewicht eines Knotens entspricht dem Kaufpreis}. Gesucht wird die Menge \(K \in V\), bei der die Summe der Gewichte der enthaltenen Knoten maximal ist. Bei der Aufnahme eines Knotens  \(A\) in die Menge \(K\) müssen ebenfalls alle Knoten, zu denen von \(A\) ein gerichteter Pfad führt, aufgenommen werden.
\end{displayquote}

\section{Eigenschaften des Graphens}
Danach habe ich für die Auswahl von geeigneten Algorithmen die Eigenschaften des Graphens untersucht:
\begin{itemize}
	\item Der Graph ist gerichtet
	\item Parallele Kanten ergeben im Kontext der Aufgabenstellung keinen Sinn, da jede Firma nur einmal erworben werden kann
	\item Reflexive Kanten ergeben ebenfalls keinen Sinn, da eine Firma sich nicht selbst vorraussetzen kann
	\item Zyklen können vorkommen
	\item Nicht jeder Knoten besitzt notwendigerweise Kanten, da einige Firmen ohne Nebenbedingungen erwerbbar sind
	\item Der Graph hat daher beliebig viele starke wie schwache Zusammenhängigkeitskomponenten
	\item Der Zahlenraum für die Knotengewichte geht nicht aus der Aufgabenstellung hervor. Logischerweise hat eine Firma jedoch einen beliebigen positiven oder negativen Wert. Daher liegt das Gewicht eines jeden Knotens in \(\mathbb{R}\).
\end{itemize}

\section{Suche nach der optimalen Teilmenge}
Mit diesen Informationen habe ich einen Algorithmus entwickelt, der die optimale Teilmenge ermittelt:

In einem ersten Schritt werden für jede Firma des Konglomerates die Firmen ermittelt, die aufgrund der Nebenbedingungen zwingend mit erworben werden müssen. Im Kontext des Graphens bedeutet dies, dass zu jedem Knoten \(A \in V\) die Menge der Knoten, zu denen von \(A\) ein Pfad führt, ermittelt wird. Dieser Menge wird der Ursprungsknoten hinzugefügt. Diese Menge hat wie auch ein Knoten ein Gewicht, dass sich aus der Summe der Gewichte der enthaltenen Knoten zusammensetzt. Jede dieser Mengen stellt einen Kauf einer Firma des Konglomerates dar, bei dem alle Nebenbedingungen berücksichtigt werden.

Allerdings gibt es darüber hinaus noch weitere gültige Käufe/Teilmengen. Denn logischerweise können in einer Transakation beliebig viele Firmen des Konglomerates erworben werden. Daher stellt zum Beispiel auch die Menge bestehend aus den Knoten \((A, B) \in V\) und den Knoten, zu denen ein gerichteter Pfad von \(A\) oder \(B\) existiert, eine gültige Transaktion im Sinne der Aufgabenstellung dar. Denn, um wieder in den Kontext der Aufgabenstellung zurückzukehren, kann der Käufer eine beliebige Firma des Konglomerates entweder unbedingt haben wollen oder den Kauf einer Firma für optional halten. 
Verallgemeinert betrachtet lässt sich eine beliebige Transaktion im Firmenkonglomerat als Pfad in einem Binärbaum darstellen. Dieser Binärbaum hat als Wurzel die leere Menge. In jeder Generation \(n\) stellt ein Knoten das Kaufen der \(n\)ten Firma samt Nebenbedingungen dar. Der andere Knoten stellt das Auslassen des Kaufes dieser Firma \(n\) dar. Die Blätter am Ende des Baumes geben dann an, welche Firmen schlussendlich samt Nebenbedingungen gekauft werden. Ein vollständiger Baum hat \(2^{h-1}\) Blätter \footnote{s. Wikipedia: \url{https://is.gd/cmZlNm}}. Da sich die Höhe aus den Generationen, also \(V\) und der Wurzel zusammensetzt, folgt daraus, dass es bis zu \(2^V\) gültige Teilmengen gibt.

\begin{wrapfigure}{r}{0.4\textwidth}
  \begin{center}
    \input{Grafiken/vereinigung.tex}
  \end{center}
  \caption{Beispielgraph}
  \label{abb:vereinigung}
\end{wrapfigure}

Die Bestimmung der aufgrund von Nebenbedingungen mitzukaufenden Firmen für \(2^V\) mögliche Kaufwünsche wird bei großer Firmenanzahl sehr zeitaufwändig, schließlich wächst die Blätteranzahl exponentiell. Allerdings lassen sich diese Mengen auch durch Vereinigung der Mengen aus dem ersten Berechnungsschritt ermitteln. Wenn Beispielsweise zum Kauf von \(A\) der Erwerb von \(M_A=\{A, C, D, R\}\) und zum Kauf von \(B\) der Erwerb von \(M_B = \{B, I, E, R\}\) erforderlich ist, ist für den Kauf von \(A\) und \(B\) der Erwerb der Menge \(M_A \cup M_B = \{A, B, C, D, E, I, R\}\) erforderlich (siehe Abbildung \ref{abb:vereinigung}). Durch die Ausnutzung dieser Eigenschaft lassen sich die \(2^V\) Mengen wesentlich schneller bestimmen, denn alle Mengen auf der linken Seite sind aus dem ersten Berechnungsschritt schon bekannt.

Die Menge mit dem höchsten Gewicht (=Wert) entspricht der Teilmenge des Graphens mit dem höchsten Wert.
Die Mengen, die aufgestellt werden müssen, lassen sich dank folgender Beobachtung erheblich reduzieren:
Knoten mit einem negativen Gewicht ergeben nur als Nebenbedingung Sinn. Denn ein ökonomisch sinnvoll handelnder Käufer würde niemals eine Firma mit einem negativen Wert freiwillig kaufen wollen. Das bedeutet, dass bei einer optimalen Auswahl auf der linken Seite, also den nicht als Nebenbedingung gekauften Firmen, nur Firmen/Knoten mit einem positiven Gewicht stehen können. Firmen ohne Wert ergeben ebenfalls keinen ökonomischen Mehrwert und können daher ebenfalls nicht auf der linken Seite stehen. Daraus folgt, dass der Binärbaum nur aus den Firmen mit positiven Wert besteht. Damit sinkt die Anzahl der zu beachtenden Teilmengen auf \(2^p\), wobei p der Anzahl der Knoten mit positivem Gewicht entspricht.

Die Anzahl der zu beachtenden Mengen kann jedoch noch weiter reduziert werden: Es gibt keinen Grund, eine positivwertige Firma nicht zu kaufen, die nur positivwertige Firmen als Nebenbedingung hat. Bei solchen Teilmengen entsteht ausschließlich Gewinn. Daher können alle Mengen aus ausschließlich positivwertigen Firmen zu einer "`Win-Win-Menge"' vereinigt werden. Diese Menge bildet nun die Wurzel des binären Baumes, da sie ja im besten Kauf enthalten sein muss. Die Anzahl der zu berücksichtigenden Mengen ist nun auf \(2^{pm}\) reduziert. \(pm\) entspricht den positivwertigen Firmen, die negativwertige Nebenbedingungen haben.

\section{Heuristik}
Damit ist jedoch nicht das Grundproblem des exponentiellen Wachstums beseitigt. Je nach verfügbarem Arbeitspeicher wird die Zustandsmenge bei einem hinreichend großem \(pm\) irgendwann so groß, dass keine weiteren Zustände mehr gespeichert werden könnnen. Auch ist die Rechenzeit bei einem sehr großen Baum extrem lange. Bei einem Konglomerat mit 169 Firmen (Quadrat-13) müssten ohne Optimierungen beispielsweise \(2^{169}=7,48\mathrm{e}{50}\) Blätter errechnet werden. Dies ist auf einem heutigen Rechner nicht in akzeptabler Zeit möglich.

Für diesen Fall muss dem Algorithmus ein heuristisches Element hinzugefügt werden. Sobald dieses eingesetzt wird, wird nicht mehr mit absoluter Sicherheit die beste Teilmenge gefunden, da Zwischenergebnisse, von denen nicht erwartet wird, dass sie Teil der besten Teilmenge sind, zur Einsparung von Speicherplatz und Verkürzung der Rechenzeit verworfen werden. In meinem Algorithmus wird, sobald die Zahl der aufgestellten Knoten ein Maximum erreicht, ein Teil der aufgestellten Knoten gelöscht. Maximum und prozentualer Anteil der zu löschenden Knoten werdem hierbei zur Laufzeit durch den Nutzer, je nach Genauigkeitsanforderung und zur Verfügung stehender Rechenzeit, festgelegt. Welche Knoten gelöscht werden, entscheidet der Algorithus nach dem Wert des Knotens. Denn es ist deutlich wahrscheinlicher, dass ein Knoten mit hohem Wert ein Zwischenergebniss zum Blatt mit dem höchsten Wert ist, als das ein Knoten mit vergleichsweise geringem Wert ein solches Zwischenergebniss darstellt. Während der Entwicklung hat sich ein Maximum 50'000 Knoten und eine Löschquote von 50\% als ein geeigneter Kompromiss aus Laufzeit und Genauigkeit herausgestellt.

Für meinen Algorithmus lautet die Antwort auf Teilaufgabe 3 "`it depends"'. Solange die Knotenzahl das vom Nutzer gesetzte Maximum unterschreitet, findet das Programm mit absoluter Sicherheit die beste Teilmenge, schließlich wird der gesamte Entscheidungsbaum aufgebaut. Sobald das Maximum überschritten wird, kann der Algorithmus nicht mehr dafür garantieren, dass das beste Ergebnis gefunden wurde. Schließlich wurde der Baum nicht komplett aufgestellt. Die Wahrscheinlichkeit, dass trotzdem das korrekte Ergebnis gefunden wird, kann der Nutzer dadurch erhöhen, dass er das Programm anweist, weniger Zwischenergebnisse zu verwerfen.